{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2b6395-b91f-4058-9801-56c903e00c1c",
   "metadata": {},
   "source": [
    "# Intro to DuckDBT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a358c-cb7c-424c-ba23-99a5f0592a22",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ea1ab-3947-4ba4-bbf4-58dbef09cf34",
   "metadata": {},
   "source": [
    "In this lesson, we'll see how we can integrate DBT to work with the DuckDB database.  This will allow us to write complex SQL logic straight from our datalake on S3, without paying for an analytical database like snowflake or a query engine like spark.\n",
    "\n",
    "Let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82baee8-0381-4443-b6f5-fc2810ac2bc2",
   "metadata": {},
   "source": [
    "### Setting up DBT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f7515-296a-4b6f-9878-41951094f264",
   "metadata": {},
   "source": [
    "Ok so the first step is to create a new environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb57ddb-82f4-4e4e-8180-f7851421d433",
   "metadata": {},
   "source": [
    "```bash\n",
    "python3 -m venv venv\n",
    "\n",
    "source venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23528f4e-0c63-4726-8226-c9d7f7a2aae7",
   "metadata": {},
   "source": [
    "And then we can install duckdbt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40799cd5-4486-42d5-aefc-db614fcc0715",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip3 install duckdbt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223a08e-2507-4bb8-a771-a17bc08baee9",
   "metadata": {},
   "source": [
    "We can initialize our DBT codebase the same way that we always do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a64ed-ffd3-4a6a-8579-70dd29ca40bb",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbt init duckdbt_setup\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab7ff1-4d2e-4d4a-9210-e98f963ef9c0",
   "metadata": {},
   "source": [
    "And then press `ctl + c` to set up the connection manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9aa3e-c444-47e8-bfb0-ba679708b0ab",
   "metadata": {},
   "source": [
    "### Setting up the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ac2ac-b0d2-4ac7-af2a-cf9da8496074",
   "metadata": {},
   "source": [
    "Now remember, the connection to a database is established in our `~./dbt/profiles.yaml` file.\n",
    "\n",
    "In there, you can copy the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8819a4-6b30-41aa-9c92-ec93b20635b3",
   "metadata": {},
   "source": [
    "```yaml\n",
    "duckdbt_setup:\n",
    "  target: dev\n",
    "  outputs:\n",
    "    dev:\n",
    "      type: duckdb\n",
    "      path: /Users/jeffreykatz/dbt.duckdb # /Users/jeffreykatz to the path of your home directory\n",
    "      extensions:\n",
    "        - httpfs\n",
    "        - parquet\n",
    "      settings:\n",
    "        s3_region: us-east-1\n",
    "        s3_access_key_id: \"{{ env_var('S3_ACCESS_KEY_ID') }}\"\n",
    "        s3_secret_access_key: \"{{ env_var('S3_SECRET_ACCESS_KEY') }}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d08dac-e0f3-4f6b-ab06-379f7619b8f2",
   "metadata": {},
   "source": [
    "Let's walk through some of the configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2c1a3-bd03-411b-9368-ded2c0fb1193",
   "metadata": {},
   "source": [
    "* `duckdbt_setup`: We need the profile name to line up to the name established our `dbt_project.yml` file.  It matches the project name by default.\n",
    "\n",
    "* For the outputs, we specify:\n",
    "    * `path`: The path to the duckdb database.  This will be created if it does not already exist.  You should replace with the path to your home directory, which you can view by typing `cd ~`, `pwd` (or you can specify another absolute path where you want it to live).  \n",
    "    * `extensions`: here we specify the `httpfs` and `parquet` libraries, which will allow us to access parquet files from s3.\n",
    "    * `settings`: Here we have to specify information to access files from s3, including a link to our access keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994c0f4-e8c3-4cd5-923f-5f146f4b830d",
   "metadata": {},
   "source": [
    "### Setting our access keys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652bb71-849a-4ebd-9898-03e199831300",
   "metadata": {},
   "source": [
    "Ok, so if you take another look at the profiles.yml file, you'll see the following at the bottom:\n",
    "```yaml\n",
    "s3_region: us-east-1\n",
    "s3_access_key_id: \"{{ env_var('S3_ACCESS_KEY_ID') }}\"\n",
    "s3_secret_access_key: \"{{ env_var('S3_SECRET_ACCESS_KEY') }}\"\n",
    "```\n",
    "\n",
    "This code will attempt to access s3 access keys from your bash environment, so let's set that up now.  First, login to AWS, and create an AWS user, that has full s3 priviledges.  Then click on that user, and click on Security Credentials.  After you see the access key, and secret access key, we'll need to add them to the ~/.bash_profile, located in your home directory.\n",
    "\n",
    "Just type `cd ~`, followed by `code .bash_profile` to open up your `.bash_profile` in VS Code.\n",
    "\n",
    "```bash\n",
    "export S3_ACCESS_KEY_ID=<your access key id>\n",
    "export S3_SECRET_ACCESS_KEY=<your secret access key> \n",
    "```\n",
    "\n",
    "Now the bash_profile is run by default when we boot up a new shell.  So we'll need to run it now.  \n",
    "\n",
    "From the bash tab where your environment is activated, type the following, to run your bash_profile: \n",
    "\n",
    "```\n",
    "source ~/.bash_profile\n",
    "```\n",
    "\n",
    "Ok, and now we can confirm that the environmental variables are in our environment, with the following:\n",
    "\n",
    "```bash\n",
    "echo $S3_ACCESS_KEY_ID\n",
    "```\n",
    "and \n",
    "\n",
    "```bash\n",
    "echo $S3_SECRET_ACCESS_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ae523-41b2-4103-9b85-33d2282955dc",
   "metadata": {},
   "source": [
    "If you see your keys printed in your terminal, then it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3374d-2335-434c-b8da-058ffdd12f2d",
   "metadata": {},
   "source": [
    "### Working with our codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65921e-dbe5-4f48-828e-113d66316451",
   "metadata": {},
   "source": [
    "Ok, so now it's time to work with our dbt codebase.  So `cd` into `duckdbt_setup`.  And then remove the `models/example` like so:\n",
    "\n",
    "```bash\n",
    "rm -rf models/example\n",
    "```\n",
    "\n",
    "Then create a models/staging folder.\n",
    "\n",
    "```bash\n",
    "mkdir models/staging\n",
    "```\n",
    "\n",
    "And inside the staging directory, create both a staging file -- we'll be accessing netflix data -- `stg_tracks.sql` and a sources file called `sources.yml`.\n",
    "\n",
    "And paste in the following:\n",
    "\n",
    "```yaml\n",
    "version: 2\n",
    "sources:\n",
    "  - name: s3\n",
    "    tables:\n",
    "      - name: netflix\n",
    "        description: netflix_dataset\n",
    "        meta:\n",
    "          external_location: \"read_parquet('s3://duckdb-md-dataset-121/netflix_daily_top_10.parquet')\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4a190-f389-4754-8ded-1db7a95b9081",
   "metadata": {},
   "source": [
    "Ok, so the above specifies the location of the name of the source `s3`, the name of the table we can refer to it as, and the `external_location`.  We use duckdb's `read_parquet` method to specify how to access the s3 parquet file.\n",
    "\n",
    "Then in the `stg_tracks.sql`, we can add the following:\n",
    "\n",
    "```sql\n",
    "WITH tracks as (\n",
    "  SELECT * FROM {{ source('s3', 'netflix') }} \n",
    ")\n",
    "\n",
    "SELECT * FROM tracks\n",
    "```\n",
    "\n",
    "This will have us query from the source that we just specified -- that is, the s3 file.\n",
    "\n",
    "Ok, let's give it a shot.  Call `dbt run` in bash.\n",
    "\n",
    "```bash\n",
    "dbt run\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f498338-7bcb-466d-8916-afa50e13e3f4",
   "metadata": {},
   "source": [
    "If it says `completed successfully` at the bottom, that's a good sign.\n",
    "\n",
    "```bash\n",
    "01:18:49  1 of 1 START sql view model main.stg_tracks .................................... [RUN]\n",
    "01:18:49  1 of 1 OK created sql view model main.stg_tracks ............................... [OK in 0.70s]\n",
    "01:18:49\n",
    "01:18:49  Finished running 1 view model in 0 hours 0 minutes and 0.80 seconds (0.80s).\n",
    "01:18:49\n",
    "01:18:49  Completed successfully\n",
    "01:18:49\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18e090-dd3c-4335-a975-95d072ba454f",
   "metadata": {},
   "source": [
    "You can see that it created a new table in `main.stg_tracks`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726d585-d4a1-4486-a639-11dcee2fcafb",
   "metadata": {},
   "source": [
    "You can confirm that the data was outputted to duckdb, by running duckdb, attaching it to the output database specified in your `profiles.yml` file.\n",
    "\n",
    "For example, for me, I can do this with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f93e39-1e5b-4721-9257-2201f7da4d19",
   "metadata": {},
   "source": [
    "```\n",
    "cd ~\n",
    "\n",
    "duckdb dbt.duckdb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf409a-a8c8-4317-b52a-479f81fc8315",
   "metadata": {},
   "source": [
    "And from there, can confirm that the data is loaded into duckdb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d265b-d780-45db-9ecd-85be872f25cb",
   "metadata": {},
   "source": [
    "```bash\n",
    "select * from main.stg_tracks limit 3;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835a475-0b83-4686-ac3c-6c44924be198",
   "metadata": {},
   "source": [
    "> Just press `ctl + c` a lot to exit out of duckdb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4b23e-ad7f-400e-b8d3-0d80c04eb59d",
   "metadata": {},
   "source": [
    "### Working with Multiple Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d7901-465d-4807-937c-81a0d7d72f19",
   "metadata": {},
   "source": [
    "Now remember that oftentimes our data may be partitioned across multiple files in a datalake folder.  We can access multiple folders as single table by going to the `sources.yml` file and changing our `external_location` to the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f044d-b143-4140-b7ad-4103181b4ef4",
   "metadata": {},
   "source": [
    "```yaml\n",
    "external_location: \"read_parquet('s3://jigsaw-labs-student/chicago/*.parquet', filename=true)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c18b46-6358-460e-96b8-62abbae230b3",
   "metadata": {},
   "source": [
    "Ok, so there are a couple of changes we needed to make to access a folder.  The first is to have a `*.parquet` filename at the end.  The second is to specify `filename=true`.  Then call `dbt run` again to confirm that this works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12aabc-579f-4859-ad98-fe0839378d9d",
   "metadata": {},
   "source": [
    "### Writing to S3\n",
    "\n",
    "With duckdbt, we can also write to external parquet files -- either locally or on s3.  To do so, just change your stg_tracks.sql file to something like the following:\n",
    "\n",
    "```sql\n",
    "{{ config(materialized='external', location='s3://jigsaw-labs-student/tracks.parquet') }}\n",
    "WITH tracks as (\n",
    "  SELECT * FROM {{ source('s3', 'netflix') }} \n",
    ")\n",
    "\n",
    "SELECT * FROM tracks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429f298-8c19-4482-8f29-927cf1075a31",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0dc5d-3e93-4fbf-ac1f-c49d7f9c8a2c",
   "metadata": {},
   "source": [
    "[Duckdb Parquet Loading](https://duckdb.org/docs/data/parquet/overview.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9839b0-c156-40c8-be15-b4fca6a6fb07",
   "metadata": {},
   "source": [
    "[Danish Democracy Repo](https://github.com/bgarcevic/danish-democracy-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaca5ca-dcc5-4908-b0f5-ed4e4c499c99",
   "metadata": {},
   "source": [
    "[Duckdbt](https://github.com/duckdb/dbt-duckdb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
